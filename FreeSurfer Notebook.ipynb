{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 181 labels from C:\\Users\\dalto\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\label\\lh.HCPMMP1.annot\n",
      "Reading labels from parcellation...\n",
      "   read 23 labels from C:\\Users\\dalto\\mne_data\\MNE-sample-data\\subjects\\fsaverage\\label\\lh.HCPMMP1_combined.annot\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import compress\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "\n",
    "# the following import is required for matplotlib < 3.2:\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import mne_nirs\n",
    "\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import h5py as h \n",
    "\n",
    "import snirf as s \n",
    "\n",
    "\n",
    "raw = r\"C:\\Users\\dalto\\Downloads\\project\\sourcedata_lm\\sub-10\\ses-01\\nirs\\sub-10_ses-01_task-wings_nirs.snirf.snirf\"\n",
    "\n",
    "#imports fsaverage model brain components\n",
    "subjects_dir = mne.datasets.sample.data_path() / 'subjects'\n",
    "mne.datasets.fetch_hcp_mmp_parcellation(subjects_dir=subjects_dir, accept=True)\n",
    "labels = mne.read_labels_from_annot('fsaverage', 'HCPMMP1', 'lh', subjects_dir=subjects_dir)\n",
    "labels_combined = mne.read_labels_from_annot('fsaverage', 'HCPMMP1_combined', 'lh', subjects_dir=subjects_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2\n",
      "0  -0.066571  0.081416  0.047017\n",
      "1  -0.064767  0.058143  0.090843\n",
      "2  -0.085904  0.018972  0.065098\n",
      "3  -0.088178  0.000578  0.046986\n",
      "4  -0.085987 -0.015713  0.029306\n",
      "5  -0.071206 -0.012874  0.107879\n",
      "6  -0.072622 -0.045692  0.069671\n",
      "7   0.062798  0.081766  0.047531\n",
      "8   0.060651  0.058824  0.091177\n",
      "9   0.081887  0.020428  0.065713\n",
      "10  0.084072  0.001807  0.047866\n",
      "11  0.082579 -0.014900  0.029868\n",
      "12  0.067128 -0.012199  0.108573\n",
      "13  0.069030 -0.045194  0.070324\n",
      "14 -0.047447  0.095404  0.073381\n",
      "15 -0.076963  0.058318  0.056967\n",
      "16 -0.086154 -0.006278  0.068867\n",
      "17 -0.065077 -0.040018  0.100009\n",
      "18  0.054578  0.083417  0.073752\n",
      "19  0.077336  0.044960  0.058661\n",
      "20  0.078973 -0.021052  0.070573\n",
      "21  0.050798 -0.052066  0.100971\n"
     ]
    }
   ],
   "source": [
    "with h.File(raw,'r+') as f:\n",
    "    orig_det = f['nirs/probe/detectorPos3D'][:,:]\n",
    "    orig_sou = f['nirs/probe/sourcePos3D'][:,:]\n",
    "    f.close()\n",
    "\n",
    "edited_det = pd.DataFrame(orig_det)\n",
    "edited_det[1] += 0\n",
    "\n",
    "edited_sou = pd.DataFrame(orig_sou)\n",
    "edited_sou[1] += 0\n",
    "\n",
    "with h.File(raw,'r+') as f:\n",
    "    f['nirs/probe/detectorPos3D'][:,:] = edited_det\n",
    "    f['nirs/probe/sourcePos3D'][:,:] = edited_sou\n",
    "    # edited_det[1] += 10\n",
    "    # edited_det[2] += 20\n",
    "\n",
    "    # edited_sou[1] += 10\n",
    "    # edited_sou[2] += 20\n",
    "    f['nirs/probe/detectorPos3D'][:,:] = edited_det\n",
    "    f['nirs/probe/sourcePos3D'][:,:] = edited_sou\n",
    "\n",
    "    # print(f\"\\n{f['nirs/probe/detectorPos3D'][:,:] == orig_det}\")\n",
    "    f.close()\n",
    "\n",
    "print(edited_det)\n",
    "\n",
    "raw_intensity = mne.io.read_raw_snirf(raw, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel types::\tfnirs_cw_amplitude: 92\n"
     ]
    }
   ],
   "source": [
    "brain = mne.viz.Brain(\n",
    "    'fsaverage', subjects_dir=subjects_dir, background='w', cortex='low_contrast', hemi='both')\n",
    "#defines brain as the command that activates the freeview mode\n",
    "\n",
    "brain.add_sensors(\n",
    "    raw_intensity.info, trans='fsaverage',\n",
    "    fnirs=['pairs','channels','sources', 'detectors'])\n",
    "#if you want to input the channels in the figure swap this line for \"fnirs=['channels', 'pairs', 'sources', 'detectors'])\"\n",
    "\n",
    "brain.show_view(azimuth=200, elevation=60, distance=400, view='rostral')\n",
    "#runs the freeview mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = sample.data_path()\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "sample_dir = data_path / \"MEG\" / \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_kwargs = dict(alpha=0.1, background=\"white\", cortex=\"low_contrast\")\n",
    "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\n",
    "\n",
    "stc = mne.read_source_estimate(sample_dir / \"sample_audvis-meg\")\n",
    "stc.crop(0.09, 0.1)\n",
    "\n",
    "kwargs = dict(\n",
    "    fmin=stc.data.min(),\n",
    "    fmax=stc.data.max(),\n",
    "    alpha=0.25,\n",
    "    smoothing_steps=\"nearest\",\n",
    "    time=stc.times,\n",
    ")\n",
    "brain.add_data(stc.lh_data, hemi=\"lh\", vertices=stc.lh_vertno, **kwargs)\n",
    "brain.add_data(stc.rh_data, hemi=\"rh\", vertices=stc.rh_vertno, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain(\"sample\", subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.add_label(\"BA44\", hemi=\"lh\", color=\"green\", borders=True)\n",
    "brain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
